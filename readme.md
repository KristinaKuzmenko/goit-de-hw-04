## Опис результатів та висновки

1. При запуску першого скрипту отримано 5 jobs:
- перші 2 відповідають за зчитування файлу, створення Spark-датафрейму, десеріалізацію типів колонок
- інші 3 jobs включають перерозподіл даних між 2 партиціями, виконання трансформацій на кожній партиції, збір даних з партицій на драйвер

2. Головною відміннюстю другого скрипту є додавання ще одного action - збір даних перед додатковою фільтрацією. 
При запуску скрипту отримано 8 jobs:
- перші дві  аналогічно означають зчитування даних з csv файлу
- для кожної дії collect відбувається по 3 jobs - в сумі 6. Це відбувається внаслідок того, що після виклику collect() Spark обчислює всі попередні трансформації, 
повертає результат на драйвер та звільняє ресурси: знімає тимчасові результати з пам’яті та не зберігає обчислені дані, якщо вони явно не кешовані.
При другому виклику collect() створюється новий DAG, який включає всі попередні трансформації, тобто Spark повторно виконує всі обчислення спочатку, створюючи 3 додаткові jobs. 
В першому ж скрипті виклик collect() був лише 1 раз в кінці, тому як наслідок lazy execution, був створений лише один DAG, і всі трансформації були здійснені за 3 jobs.

3. В третьому скрипті додано кешування результатів першої трансформації. Як результат кількість jobs зменшилась. 
Після першого виклику collect() ствлрилося 3 jobs, і результат обчислень був збережений в пам'яті. Тепер після другого виклику collect() Spark замість виконання всіх трансформацій спочатку 
зчитує результат проміжних обчислень з пам'яті і виконує лише другу фільтрацію, яка вже не потребує shuffle між партиціями. Тому створено лише 2 додаткові jobs замість 3, скорочено час виконання програми.
